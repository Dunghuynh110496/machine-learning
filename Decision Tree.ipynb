{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "## Model\n",
    "A decision tree maps input $x \\in {R^d}$ to output y using binary decision rules:\n",
    " - Each node in the tree has a splitting rule:\n",
    "\n",
    "$$h\\left( x \\right) = 1\\left\\{ {{x_j} > t} \\right\\}$$\n",
    "\n",
    "for some dimension $j$ of $x$ and $t \\in R$\n",
    "\n",
    " - Each leaf node is associated with an output value (outputs can repeat)\n",
    "\n",
    "Using these transition rules, a path to a leaf node gives the prediction.\n",
    "\n",
    "## How to fit it\n",
    "\n",
    "The step to build the basic Decision Tree:\n",
    "\n",
    "- Step 1: we will start the process with a single leaf node that contains all data.\n",
    "\n",
    "- Step 2: Loop through the following steps:\n",
    "\n",
    "    - Calculate the leaf to split that reduces the most inaccuracy.\n",
    "    - Filter the data: one side is the data that is lower than splitng rule and vice versa.\n",
    "- Stopping rule duscussed later.\n",
    "\n",
    "\n",
    "###Build the Regression Tree:\n",
    "For the  Regression Tree: The squared error is a natural way to define the splitting rule.\n",
    "\n",
    "For $M$ regions of the space, ${R_1},..,{R_M}$,\n",
    "the prediction function is\n",
    "\n",
    "$$f\\left( x \\right) = \\sum\\limits_{m = 1}^M {{c_m}1\\left\\{ {x \\in {R_m}} \\right\\}} $$\n",
    "\n",
    "So, for a fixed $M$, we need $R_m$ and $c_m$.\n",
    "\n",
    "Goal: Try to minimize ${\\sum\\limits_i {\\left( {{y_i} - f\\left( {{x_i}} \\right)} \\right)} ^2}$.\n",
    "\n",
    "1. Find $c_m$ given $R_m$: Simply the average of all $y_i$ for which $x \\in R_m$.\n",
    "2. How do we find regions? Consider splitting region $R$ at value $s$ of $dim j$:\n",
    " - define ${R^ - }\\left( {j,s} \\right) = \\left\\{ {{x_i} \\in R|{x_i}\\left( j \\right) \\leqslant s} \\right\\}$ and ${R^ + }\\left( {j,s} \\right) = \\left\\{ {{x_i} \\in R|{x_i}\\left( j \\right) > s} \\right\\}$\n",
    " - For each dimension $j$, calculate the best splitting point $s$ for that dimension.\n",
    " -  Do this for each region (leaf node). Pick the one that reduces the objective most.\n",
    "\n",
    "###Build the Classification Tree:\n",
    "For the Classification Tree:  Need some measure of how badly a region classifies data and how much it can improve if itâ€™s split.\n",
    "\n",
    "K-class problem: For all $ x \\in R_m$, let $p_k$ be empirical fraction labeled $k$.\n",
    "\n",
    "Measures of quality of Rm include:\n",
    "\n",
    "1. Classification error: $1 - {\\max _k}{p_k}$.\n",
    "2. Gini index: $1 - \\sum\\limits_k {{p_k}^2} $.\n",
    "3. Entropy: $ - \\sum\\limits_k {{p_k}\\ln {p_k}} $\n",
    "\n",
    "\n",
    "## How to use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "\tdef __init__(self, split_feature,split_value, left_child, right_child,label):\n",
    "\t\tself.split_feature = split_feature\n",
    "\t\tself.split_value = split_value\n",
    "\t\tself.left_child = left_child\n",
    "\t\tself.right_child = right_child\n",
    "\t\tself.label = label\n",
    "\n",
    "class DecisionTree:\n",
    "\tdef __init__(self):\n",
    "\t\tpass\n",
    "\n",
    "\tdef fit(self, train):\n",
    "\t\ttrain = train.to_numpy()\n",
    "\t\tself.tree = self.build_tree(train)\n",
    "\t\n",
    "\tdef build_tree(self, Train):\n",
    "\t\tgini_label = self.compute_gini(train[:,0])\n",
    "\t\tif gini_label < 0.5:\n",
    "\t\t\treturn None\n",
    "\t\tbest_gini, best_split, best_feature = float(\"inf\"), 0.0, 0.0\n",
    "\t\tfor i in np.random.randint(1, 785, size=100):\n",
    "\t\t\tuniques = np.unique(train[:,i])\n",
    "\t\t\tfor unique in uniques:\n",
    "\t\t\t\tregion1 = train[train[:,i] < unique][:,0]\n",
    "\t\t\t\tregion2 = train[train[:,i] >= unique][:,0]\n",
    "\t\t\t\tgini1 = self.compute_gini(region1)\n",
    "\t\t\t\tgini2 = self.compute_gini(region2)\n",
    "\t\t\t\tgini = gini1*(len(region1)/len(train)) +  gini1*(len(region2)/len(train))\n",
    "\t\t\t\tif gini < best_gini:\n",
    "\t\t\t\t\tbest_gini, best_split, best_feature = gini, unique, i\n",
    "\t\tlabel = np.bincount(train[:,0]).argmax()\n",
    "\t\tleft_node = self.build_tree(train[train[:,best_feature] < best_split])\n",
    "\t\tright_node = self.build_tree(train[train[:,best_feature] >= best_split])\n",
    "\t\treturn Node(best_feature, best_split, left_node, right_node, label) \n",
    "\n",
    "\tdef compute_gini(self,y):\n",
    "\t\tdic = {}\n",
    "\t\tfor i in y:\n",
    "\t\t\tif i not in  dic:\n",
    "\t\t\t\tdic[i] = 0\n",
    "\t\t\tdic[i] += 1\n",
    "\t\tp = 0\n",
    "\t\tfor i in dic:\n",
    "\t\t\tp += (dic[i]/len(y))**2\n",
    "\t\tgini = 1 - p\n",
    "\t\treturn gini \n",
    "\n",
    "\tdef predict(self, test):\n",
    "\t\tnode = self.tree\n",
    "\t\twhile node.left_child or node.left_child:\n",
    "\t\t\tif test[node.split_feature] < node.split_value:\n",
    "\t\t\t\tnode = node.left_child\n",
    "\t\t\telse:\n",
    "\t\t\t\tnode = node.right_child\n",
    "\t\treturn node.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "df_test = pd.read_csv(\"data/test.csv\")\n",
    "classifier = DecisionTree()\n",
    "classifier.fit(df_train)\n",
    "f = open(\"outputs/submission2.csv\", \"w\")\n",
    "f.write(\"ImageId,Label\\n\" )\n",
    "test = df_test\n",
    "test = test.to_numpy()\n",
    "for i in range(len(test)):\n",
    "  a = classifier.predict(test[i])\n",
    "  f.write(str(i+1) + \",\" + str(a) +\"\\n\")\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
